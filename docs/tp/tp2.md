---
layout: default
title: TP 2
parent: Travaux pratiques
permalink: tp/tp2
---

# TP 2 ‚Äî Migration de paradigme des bases de donn√©es  
**Des bases relationnelles (SQL) vers les bases orient√©es documents (NoSQL)**  
**Dur√©e** : 3 semaines ¬∑ **√âquipe** : Individuel

---

## Contexte

Vous √™tes **ing√©nieur¬∑e de donn√©es** sur une plateforme e-commerce. Cette plateforme re√ßoit **des millions de requ√™tes par seconde** et les bases relationnelles actuelles ne suffisent plus en performance/scalabilit√©. L‚Äôentreprise d√©cide donc de migrer vers une base **NoSQL (MongoDB)**.

Votre mission :  
1) **Exporter** les donn√©es de **PostgreSQL** au format **JSON** ;  
2) **Mod√©liser** et **importer** dans **MongoDB** (orient√© document) ;  
3) **Comparer** et **traduire** vos analyses SQL en **pipelines d‚Äôagr√©gation** MongoDB.

---

## Objectifs d‚Äôapprentissage

- Comprendre la migration **PostgreSQL ‚Üí MongoDB**  
- Savoir **exporter / importer** des **JSON**  
- Mod√©liser des collections (**imbriqu√©** vs **r√©f√©renc√©**)  
- Cr√©er et **justifier** des **index** (date, texte, g√©ospatial)  
- Traduire des **requ√™tes SQL** en **pipelines MongoDB**  
- Mettre en ≈ìuvre des requ√™tes avanc√©es : **g√©ospatial**, **full-text**, **bucket**, **facet**

---

## Pr√©requis

Nous utilisons une **installation locale de MongoDB**.  
‚ö†Ô∏è **Mongo Atlas** peut √™tre **limit√©** pour ce TP (volumes interm√©diaires lors des transformations).

### Logiciels √† installer

- **MongoDB 6.0+** ‚Äî <https://www.mongodb.com/try/download/community>  
- **MongoDB Tools** (mongoimport / mongoexport) ‚Äî <https://www.mongodb.com/try/download/database-tools>  
- **mongosh** & **MongoDB Compass** ‚Äî Docs Compass : <https://docs.mongodb.com/compass/current/>  
- **Outils TP1** (psql / pgAdmin)

### Acronymes utiles

| Acronyme | Signification | Exemple / Description |
|---|---|---|
| CRUD | Create / Read / Update / Delete | Op√©rations de base |
| DDL | Data Definition Language | `CREATE`, `ALTER` |
| DML | Data Manipulation Language | `INSERT`, `UPDATE`, `DELETE` |
| DQL | Data Query Language | `SELECT` |
| I/O | Input / Output | Lecture/√©criture disque |

---

# Laboratoire

## 1) Base de donn√©es initiale (PostgreSQL)

T√©l√©chargez **`dump_tp1_orig.sql`** (Moodle ‚Üí *Ressources TP 2*), puis restaurez la base **avant** de commencer.

### Consignes
- Indiquez dans votre **README** la m√©thode utilis√©e (**ligne de commande** ou **pgAdmin**).
- La base **`tp1_ind500`** doit contenir **11 tables brutes** avant tout export JSON.

### M√©thode rapide (CLI)

```bash
# Cr√©ation de la base
psql -h localhost -U postgres -d postgres \
  -c "CREATE DATABASE tp1_ind500 ENCODING 'UTF8'"

# Restauration
pg_restore -h localhost -U postgres -d tp1_ind500 \
  --clean --no-owner --no-privileges \
  "....\dump_tp1_orig.sql"

# V√©rification (liste des tables)
psql -h localhost -U postgres -d tp1_ind500 -c "\dt"
````

### M√©thode graphique (pgAdmin)

1. Cr√©ez la base **`tp1_ind500`**.
2. Clic droit ‚Üí **Restore‚Ä¶**

   * Format : *Custom or tar*
   * Fichier : `dump_tp1_orig.sql`
3. Lancez la restauration : le message **‚ÄúProcess returned exit code 0‚Äù** confirme la r√©ussite.
   **Guide** : [https://www.pgadmin.org/docs/pgadmin4/latest/backup\_and\_restore.html#restore](https://www.pgadmin.org/docs/pgadmin4/latest/backup_and_restore.html#restore)

> ‚ÑπÔ∏è Tout le monde part du **m√™me dump**. La normalisation et les requ√™tes avanc√©es se feront **dans MongoDB**.

---

## 2) Sch√©ma source et export JSON

Toutes les tables PostgreSQL doivent √™tre **export√©es en JSON** vers `data/`.

### 2.1 √âtapes

1. Connexion :

   ```bash
   psql -U postgres -d tp1_ind500 -h localhost
   ```

2. Encodage :

   ```sql
   \encoding UTF8
   ```

3. Export **une table** (ex. g√©n√©rique) :

   ```sql
   \copy (
     SELECT row_to_json(t)
     FROM public.<table> AS t
   ) TO 'C:/Data/<table>.json';
   ```

   üìñ `row_to_json` : [https://www.postgresql.org/docs/current/functions-json.html](https://www.postgresql.org/docs/current/functions-json.html)

4. R√©p√©tez pour **chaque table** du sch√©ma.

### 2.2 R√®gle de correspondance (√† v√©rifier)

* **1 ligne PostgreSQL** ‚Üí **1 document JSON**
* Exemple : `orders` a **98 000** lignes ‚Üí `orders.json` = **98 000** objets.

---

## 3) Import dans MongoDB

### 3.1 S√©lection de la base

```javascript
use tp2_ind500
```

> La base est cr√©√©e **automatiquement** √† la premi√®re √©criture (pas de `CREATE DATABASE`).

### 3.2 (Optionnel) Pr√©-cr√©ation pour Compass

```javascript
db.createCollection("orders");
```

### 3.3 Import JSON (un fichier par collection)

```bash
mongoimport \
  --uri "mongodb://localhost:27017" \
  --db tp2_ind500 \
  --collection <collection> \
  --file "C:/Data/<table>.json" \
  --drop
```

* Remplacez `<collection>` et `<table>` (souvent m√™mes noms).
* `--drop` √©vite les doublons si vous rejouez.

### 3.4 V√©rification

```javascript
db.<collection>.countDocuments()
```

Doit **√©galer** le nombre de lignes export√©es depuis PostgreSQL.

**Livrable** : script d‚Äôimport (`import.sh` / `import.ps1`) **ou** commandes list√©es dans `README.md`.

---

## 4) Mod√©lisation MongoDB

### 4.1 Rappels : imbriqu√© vs r√©f√©renc√©

**Imbriqu√© (embedded)** : sous-documents dans le m√™me document.

* **Quand** : relations **1:1** ou **1\:n** **faible volume**.
* **+** : une seule lecture ; logique simple.
* **‚Äì** : documents lourds si volume augmente ; duplication possible.

**R√©f√©renc√©** : on garde l‚Äô**identifiant** vers une autre collection.

* **Quand** : **n\:n**, gros volumes, acc√®s s√©par√©.
* **+** : √©vite la duplication ; gestion ind√©pendante.
* **‚Äì** : requ√™tes plus complexes ; **plusieurs lectures** ; d√©pend des **index**.

### 4.2 Documentation du mod√®le (`model.md` + rapport)

Pour **chaque collection** (ex. `orders`, `customers`, etc.) :

1. **Champs racine** & **sous-docs imbriqu√©s**
2. **R√©f√©rences** (ids vers autres collections)
3. **Justification m√©tier** (2‚Äì3 phrases : pourquoi imbriquer / r√©f√©rencer)
4. **Sch√©ma visuel** (draw\.io / Lucidchart)

> `model.md` est la **source de v√©rit√©** pour l‚Äôimpl√©mentation (5).

### 4.3 Import ‚Üí OK, passons √† la mat√©rialisation (impl√©ment√©e en 5)

---

## 5) Mat√©rialisation du mod√®le (obligatoire)

Cr√©er **`00-build-modeled.js`** (ex√©cut√© dans **mongosh**) pour construire vos collections **mod√©lis√©es** (`tp2_*`) √† partir des **collections brutes**.

* Respectez **strictement** vos choix de `model.md`.
* Pipelines **lisibles et comment√©s** ; utilisez `$lookup`, `$set`, `$unset`, `$project`, **\$merge** (idempotent).

### Exigences

* **Index de jointure** cr√©√©s **avant** d‚Äôex√©cuter (voir ¬ß7).
* **1 doc racine** ‚Üí **1 doc mod√©lis√©** (m√™mes cardinalit√©s) ; toute diff√©rence doit √™tre **expliqu√©e**.
* **Rejouable** : relancer le script **ne duplique pas**.

### Livrables (5.2)

* `00-build-modeled.js`
* **Captures Compass** : 1 doc **brut** vs 1 doc **mod√©lis√©** (par collection)
* **Tableau des collections mod√©lis√©es** (dans `results.md`) :

  * `Collection mod√©lis√©e | Sources | Count attendu | Count obtenu | Commentaire`

---

## 6) Normalisation des donn√©es

**But** : uniformiser les textes pour de meilleures agr√©gations / recherches.

### Champs cibl√©s (min.)

* `customer_city`, `seller_city` ‚Üí villes normalis√©es
* `review_comment_message` ‚Üí texte nettoy√©

**R√®gles** : cr√©er de **nouveaux** champs `*_norm` (**ne pas √©craser** l‚Äôoriginal) :

* minuscules ;
* retrait **accents** ;
* retrait **symboles** inutiles ;
* trim / espaces normalis√©s.

**O√π** :

* Avant 5 (sur **brut**) et propagation ; **ou**
* Apr√®s 5 (directement sur **`tp2_*`**).
  Expliquez votre choix dans le rapport.

### Livrables (6.3)

* `01-normalize.js` (comment√©)
* Captures **avant / apr√®s** (3 docs **par champ**)
* Note dans `README.md` : o√π + pourquoi + r√®gles + cas particuliers

---

## 7) Cr√©ation et justification des index

**Objectifs** :

* **Date d‚Äôachat** ‚Üí tri/filtre rapide
* **Texte** ‚Üí recherche plein-texte sur commentaires
* **G√©ospatial** ‚Üí proximit√© (2dsphere)

### √Ä faire

* Script **`02-create-indexes.js`** (comment√©, chemins adapt√©s)
* Ex√©cuter dans **mongosh**
* V√©rifier dans **Compass ‚Üí Indexes** (captures)

**Livrables (7.2)**

* `02-create-indexes.js`
* Captures :

  * 2 index sur `tp2_orders` (date, texte)
  * 1 index sur `tp2_sellers_geo` (2dsphere)
* `README.md` : 1 ligne **par index** ‚Üí **but + test + plan observ√©**

**Exemples de tests (Explain)**

* Tri date :

  ```javascript
  db.tp2_orders.find().sort({ order_purchase_timestamp: 1 }).explain("executionStats")
  ```
* Plein-texte :

  ```javascript
  db.tp2_orders.find({ $text: { $search: "retard" } }).explain("executionStats")
  ```
* G√©o (2dsphere) :

  ```javascript
  db.tp2_sellers_geo.find({
    "geo.location": {
      $near: {
        $geometry: { type: "Point", coordinates: [ -73.56, 45.5 ] }, // [lng, lat]
        $maxDistance: 10000
      }
    }
  }).explain("executionStats")
  ```

> Rappels : **1 seul index texte par collection** ; coordonn√©es `[longitude, latitude]` ; cr√©ez les index **avant** de tester (√©viter **COLLSCAN**).

---

## 8) Traduction SQL ‚Üí pipelines MongoDB (travail individuel)

* **Groupe A** : Q1-A ‚Üí Q5-A
* **Groupe B** : Q1-B ‚Üí Q5-B

> Le reste du TP est commun.

**R√®gle d‚Äôor** : partez des collections **mod√©lis√©es** (`tp2_*`). D√©rogation ‚Üí **justification** (1‚Äì2 phrases) requise.

### √Ä r√©aliser (8.1)

* Fichier **`03-queries.js`**

  * Pour **chaque question** : collez l‚Äô**√©nonc√© SQL** (en **commentaire**)
  * √âcrivez le **pipeline** √©quivalent
  * **Commentez** chaque stage (`$match`, `$unwind`, `$group`, ‚Ä¶)

* **Ex√©cution + capture** : mongosh ou Compass ‚Üí 1 **capture** (r√©sultat final) **par question**

* **`results.md`** : pour chaque question

  * ID (ex. Q1-A)
  * **1‚Äì2 phrases** d‚Äô**interpr√©tation** (ex. ¬´ 215 commandes exp√©di√©es en retard ¬ª)

---

## 9) Requ√™tes avanc√©es (obligatoires, travail individuel)

Travaillez sur vos **collections mod√©lis√©es** (`tp2_*`) et codez **4 pipelines** (fichier **`04-advanced-queries.js`**), chacun pr√©c√©d√© d‚Äôun **bref commentaire** :

1. **\$near** : clients √† moins de **10 km** d‚Äôun point
2. **\$text** : commentaires contenant **¬´ d√©fectueux ¬ª** ou **¬´ retard ¬ª**
3. **\$bucket** : tranches de **d√©lai de conversion** (0-7, 8-30, 31-90, >90 jours) sur `tp2_leads`
4. **\$facet** : en **1 requ√™te**, **top 5 produits** ET **top 5 vendeurs** par CA

**Livrables (9.2)**

* `04-advanced-queries.js` (4 pipelines, comment√©s)
* 4 **captures** (PNG/JPG) montrant :

  * `$near` : distances
  * `$text` : documents trouv√©s
  * `$bucket` : d√©compte par tranche
  * `$facet` : deux **tops 5**
* `results.md` : **1 phrase** par pipeline (ex. ¬´ 20 clients dans 10 km ¬ª)

---

## 10) Environnement d‚Äôex√©cution

**Option A ‚Äî Local** : installez MongoDB 6.0+, d√©marrez le service, test :

```bash
mongosh "mongodb://localhost:27017" --eval "db.runCommand({ ping: 1 })"
```

**Option B ‚Äî Conteneur (recommand√©)**

```bash
# Podman
podman run -d --name mongo \
  -p 27017:27017 -v mongodata:/data/db \
  --restart unless-stopped mongo:6.0

# Docker
docker run -d --name mongo \
  -p 27017:27017 -v mongodata:/data/db \
  --restart unless-stopped mongo:6.0
```

---

## 11) Livrable

### 11.1 Archive √† remettre

* Nom : **`TP_MongoDB_<votre_nom>.zip`**

### 11.2 Arborescence attendue

```
TP_MongoDB_<votre_nom>/
‚îú‚îÄ data/                      # JSON export√©s depuis PostgreSQL
‚îÇ  ‚îú‚îÄ orders.json
‚îÇ  ‚îî‚îÄ ...
‚îú‚îÄ import.sh | import.ps1     # mongoimport rejouable (--drop)
‚îú‚îÄ 00-build-modeled.js        # mat√©rialisation tp2_* ($lookup/$set/$unset/$merge)
‚îú‚îÄ 01-normalize.js            # champs *_norm (villes, commentaires)
‚îú‚îÄ 02-create-indexes.js       # index (date, texte, 2dsphere)
‚îú‚îÄ 03-queries.js              # 5 pipelines (votre groupe), SQL en t√™te + commentaires
‚îú‚îÄ 04-advanced-queries.js     # 4 pipelines : $near, $text, $bucket, $facet
‚îú‚îÄ captures/                  # preuves (noms explicites)
‚îÇ  ‚îî‚îÄ ...
‚îú‚îÄ README.md                  # ex√©cution pas-√†-pas, ordre des scripts, v√©rifs
‚îú‚îÄ model.md                   # sch√©ma, embedded vs r√©f√©renc√©, justifs, diagramme
‚îî‚îÄ rapport_final.pdf          # synth√®se, limites, pistes d'am√©lioration
```

### 11.3 Crit√®res d‚Äôacceptation (r√©sum√©)

* **data/** : JSON **=** lignes SQL (reportez les comptes dans `results.md`)
* **00-build-modeled.js** : idempotent, pas de doublons, cardinalit√©s respect√©es
* **01-normalize.js** : champs `_norm`, d√©monstration **avant/apr√®s**
* **02-create-indexes.js** : index OK, **Explain** sans **COLLSCAN** √©vitable
* **03-queries.js** : 5 pipelines (groupe), **SQL en t√™te**, **stages comment√©s**
* **04-advanced-queries.js** : 4 pipelines + **captures**
* **README.md** : environnement, commandes, **ordre des scripts**, v√©rifs
* **rapport\_final.pdf** : clart√©, justification, limites, pistes d‚Äôam√©lioration

### 11.4 Check-list (ultime)

* [ ] Export JSON : comptes **OK**
* [ ] Import MongoDB : comptes **OK**
* [ ] Mod√©lisation : **tp2\_**\* g√©n√©r√©es, **idempotent**
* [ ] Normalisation : champs `_norm` + **captures**
* [ ] Index : **date**, **texte**, **2dsphere** + **Explain**
* [ ] SQL‚ÜíMongo : 5 pipelines **comment√©s** + **captures**
* [ ] Avanc√©es : 4 pipelines + **captures**
* [ ] README + `results.md` complets
* [ ] Rapport final livr√©

---

## Annexes

### R√©f√©rences

**PostgreSQL / pgAdmin**

* row\_to\_json : [https://www.postgresql.org/docs/current/functions-json.html](https://www.postgresql.org/docs/current/functions-json.html)
* Restauration pgAdmin : [https://www.pgadmin.org/docs/pgadmin4/latest/backup\_and\_restore.html#restore](https://www.pgadmin.org/docs/pgadmin4/latest/backup_and_restore.html#restore)

**MongoDB ‚Äî T√©l√©chargements & Outils**

* Community Server : [https://www.mongodb.com/try/download/community](https://www.mongodb.com/try/download/community)
* Database Tools : [https://www.mongodb.com/try/download/database-tools](https://www.mongodb.com/try/download/database-tools)
* Compass (docs) : [https://docs.mongodb.com/compass/current/](https://docs.mongodb.com/compass/current/)

**MongoDB ‚Äî Documentation**

* Data model design : [https://docs.mongodb.com/manual/core/data-model-design/](https://docs.mongodb.com/manual/core/data-model-design/)
* Aggregation pipeline : [https://docs.mongodb.com/manual/core/aggregation-pipeline/](https://docs.mongodb.com/manual/core/aggregation-pipeline/)
* Aggregation operators : [https://docs.mongodb.com/manual/reference/operator/aggregation/](https://docs.mongodb.com/manual/reference/operator/aggregation/)
* `$lookup` : [https://docs.mongodb.com/manual/reference/operator/aggregation/lookup/](https://docs.mongodb.com/manual/reference/operator/aggregation/lookup/)
* `mongoimport` : [https://docs.mongodb.com/manual/reference/program/mongoimport/](https://docs.mongodb.com/manual/reference/program/mongoimport/)
* Indexes : [https://docs.mongodb.com/manual/indexes/](https://docs.mongodb.com/manual/indexes/)
* Geospatial : [https://docs.mongodb.com/manual/geospatial-queries/](https://docs.mongodb.com/manual/geospatial-queries/)
* Text search : [https://docs.mongodb.com/manual/text-search/](https://docs.mongodb.com/manual/text-search/)
* `$bucket` : [https://docs.mongodb.com/manual/reference/operator/aggregation/bucket/](https://docs.mongodb.com/manual/reference/operator/aggregation/bucket/)
* `$facet` : [https://docs.mongodb.com/manual/reference/operator/aggregation/facet/](https://docs.mongodb.com/manual/reference/operator/aggregation/facet/)

---

**Bon TP !**
Pour toute question, consultez la documentation MongoDB ou le forum du cours.
